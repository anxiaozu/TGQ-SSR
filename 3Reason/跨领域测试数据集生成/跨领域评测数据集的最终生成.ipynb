{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 金融领域数据集生成  都需要生成4种prompt 才能验证我们方法在领域迁移上的有效性\n",
    "import json\n",
    "import re\n",
    "\n",
    "file_prefix = \"finbench\"\n",
    "dataset = \"金融数据集构建领域迁移\"\n",
    "\n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query.json\",'r') as file:\n",
    "    data = json.load(file)\n",
    "new_data = []    \n",
    "for row in data:\n",
    "    for key,value in row.items(): \n",
    "        instruction = '请将以下自然语言转换为图数据库的Cypher查询:\\n'+key\n",
    "        new_data.append({'instruction':instruction,'output':value+\";\",\"input\":\"\"})    \n",
    "with open(f'{file_prefix}_normal.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False) \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query_train.json\",'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "new_data = []     \n",
    "for row in data:\n",
    "    new_row ={\"input\":\"\"}\n",
    "    new_row[\"instruction\"] = row['instruction']\n",
    "    new_row[\"output\"] = row[\"output\"]+\";\"\n",
    "    new_data.append(new_row)\n",
    "        \n",
    "with open(f'{file_prefix}_with_vector_prompt.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False)\n",
    "    \n",
    "    \n",
    "\n",
    "schema_ldbc_info = \"\"\n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/schema_{file_prefix}_info.json\", \"r\",encoding=\"utf-8\") as file:\n",
    "    schema_ldbc_info= \"已知数据库的schema信息如下：\\n\"+ json.dumps(json.load(file), ensure_ascii=False) \n",
    "    \n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query.json\",'r') as file:\n",
    "    data = json.load(file) \n",
    "new_data = []         \n",
    "for row in data:\n",
    "    for key,value in row.items(): \n",
    "        instruction = schema_ldbc_info+\"\\n请将以下自然语言转换为图数据库的Cypher查询:\\n\"+key\n",
    "        new_data.append({'instruction':instruction,'output':value+\";\",\"input\":\"\"})    \n",
    "        \n",
    "with open(f'{file_prefix}_with_schema_prompt.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False) \n",
    "    \n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query_train.json\",'r') as file:\n",
    "    data = json.load(file) \n",
    "new_data = []         \n",
    "for row in data:\n",
    "    new_row ={\"input\":\"\"}\n",
    "    # instruction = instruction.replce('\\n请将以下自然语言翻译为对该数据库的Cypher查询:\\n','')\n",
    "    new_row[\"instruction\"] = schema_ldbc_info+\"\\n\"+ row['instruction'] \n",
    "    new_row[\"output\"] = row[\"output\"]+\";\"\n",
    "    new_data.append(new_row)\n",
    "        \n",
    "with open(f'{file_prefix}_with_schema_vector_prompt.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False)       \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 金融领域数据集生成  都需要生成4种prompt 才能验证我们方法在领域迁移上的有效性\n",
    "import json\n",
    "import re\n",
    "\n",
    "file_prefix = \"medical\"\n",
    "dataset = \"医疗数据集构建领域迁移\"\n",
    "\n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query.json\",'r') as file:\n",
    "    data = json.load(file)\n",
    "new_data = []    \n",
    "for row in data:\n",
    "    for key,value in row.items(): \n",
    "        instruction = '请将以下自然语言转换为图数据库的Cypher查询:\\n'+key\n",
    "        new_data.append({'instruction':instruction,'output':value+\";\",\"input\":\"\"})    \n",
    "with open(f'{file_prefix}_normal.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False) \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query_train.json\",'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "new_data = []     \n",
    "for row in data:\n",
    "    new_row ={\"input\":\"\"}\n",
    "    new_row[\"instruction\"] = row['instruction']\n",
    "    new_row[\"output\"] = row[\"output\"]+\";\"\n",
    "    new_data.append(new_row)\n",
    "        \n",
    "with open(f'{file_prefix}_with_vector_prompt.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False)\n",
    "    \n",
    "    \n",
    "\n",
    "schema_ldbc_info = \"\"\n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/schema_{file_prefix}_info.json\", \"r\",encoding=\"utf-8\") as file:\n",
    "    schema_ldbc_info= \"已知数据库的schema信息如下：\\n\"+ json.dumps(json.load(file), ensure_ascii=False) \n",
    "    \n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query.json\",'r') as file:\n",
    "    data = json.load(file) \n",
    "new_data = []         \n",
    "for row in data:\n",
    "    for key,value in row.items(): \n",
    "        instruction = schema_ldbc_info+\"\\n请将以下自然语言转换为图数据库的Cypher查询:\\n\"+key\n",
    "        new_data.append({'instruction':instruction,'output':value+\";\",\"input\":\"\"})    \n",
    "        \n",
    "with open(f'{file_prefix}_with_schema_prompt.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False) \n",
    "    \n",
    "with open(f\"/home/work/liuytest/大论文/{dataset}/tongyi_query_pair_query_train.json\",'r') as file:\n",
    "    data = json.load(file) \n",
    "new_data = []         \n",
    "for row in data:\n",
    "    new_row ={\"input\":\"\"}\n",
    "    # instruction = instruction.replce('\\n请将以下自然语言翻译为对该数据库的Cypher查询:\\n','')\n",
    "    new_row[\"instruction\"] = schema_ldbc_info+\"\\n\"+ row['instruction'] \n",
    "    new_row[\"output\"] = row[\"output\"]+\";\"\n",
    "    new_data.append(new_row)\n",
    "        \n",
    "with open(f'{file_prefix}_with_schema_vector_prompt.json', 'w') as file:\n",
    "    json.dump(new_data,file,indent=4 ,ensure_ascii=False)       \n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
