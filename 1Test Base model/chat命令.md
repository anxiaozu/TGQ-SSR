1. 命令
```
cd /home/work/liuytest/LLaMA-Factory
conda activate pytorch21
```
## qwen
```
llamafactory-cli chat examples/inference/Qwen2.50.5B_base.yaml
llamafactory-cli chat examples/inference/Qwen2.51.5B_base.yaml
llamafactory-cli chat examples/inference/Qwen2.53_base.yaml
llamafactory-cli chat examples/inference/Qwen2.57B_base.yaml
llamafactory-cli chat examples/inference/Qwen2.514B_base.yaml
llamafactory-cli chat examples/inference/Qwen2.532B_base.yaml
```
## glm
```
llamafactory-cli chat examples/inference/GLM49B_base.yaml
```
## llama
```
llamafactory-cli chat examples/inference/LLama7B_base.yaml 
```

## gemma
 llamafactory-cli chat examples/inference/gemma9B_base.yaml 