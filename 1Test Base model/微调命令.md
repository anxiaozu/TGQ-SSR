1. 命令
```
cd /home/work/liuytest/LLaMA-Factory
conda activate pytorch21
```
## qwen
```
 llamafactory-cli train examples/train_lora/Qwen2.532B_fitune_base.yaml
llamafactory-cli train examples/train_lora/Qwen2.57B_fitune_base.yaml
llamafactory-cli train examples/train_lora/Qwen2.53B_fitune_base.yaml
llamafactory-cli train examples/train_lora/Qwen2.51.5B_fitune_base.yaml
llamafactory-cli train examples/train_lora/Qwen2.50.5_fitune_base.yaml
```
## glm
```
llamafactory-cli train examples/train_lora/GLM49B_fitune_base.yaml
```
## llama
```
 ASCEND_RT_VISIBLE_DEVICES=1,2,3  llamafactory-cli train examples/train_lora/LLama7B_fitune_base.yaml
```

## baichuan2 不好用 报错 不能用
ASCEND_LAUNCH_BLOCKING=1 llamafactory-cli train examples/train_lora/Baichuan2_7B_fitune_base.yaml

## gemma
 llamafactory-cli train examples/train_lora/gemma9B_fitune_base.yaml 

 